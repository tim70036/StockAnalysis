{
 "cells": [
  {
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "DAYS_IN_YEAR = 252\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "def get_ticker_from_yahoo(ticker: str, start: datetime, end: datetime):\n",
    "    \"\"\" Get ticker from Yahoo Finance.\n",
    "    \"\"\"\n",
    "    return yf.Ticker(ticker).history(start=start, end=end)\n",
    "\n",
    "\n",
    "def get_ticker_data(ticker: str, start: datetime, end: datetime):\n",
    "    \"\"\" Get the details stats for a stock ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): the ticker symbol on Yahoo Finance.\n",
    "        start (datetime): start time of data.\n",
    "        end (datatime): end time of data.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: contains the daily stats of the ticker.\n",
    "    \"\"\"\n",
    "    data = get_ticker_from_yahoo(ticker, start, end)\n",
    "    data['Change'] = data['Close'].pct_change()\n",
    "    data['Gross Return'] = data['Change'] + 1\n",
    "    data['Log Return'] = np.log(data['Gross Return'])\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_risk_free_return(start: datetime, end: datetime):\n",
    "    \"\"\" Get risk-free return.\n",
    "\n",
    "    The risk-free return is yielded by 13 Week Treasuray Bill.\n",
    "    Note that the data from Yahoo Finance represent is annualized return.\n",
    "    Each daily value contains annualized return %.\n",
    "\n",
    "    Args:\n",
    "        start (datetime): start time of data.\n",
    "        end (datatime): end time of data.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: contains the daily stats of risk-free return.\n",
    "    \"\"\"\n",
    "    irx = get_ticker_from_yahoo('^IRX', start ,end)\n",
    "    irx['Annaul Log Return'] = np.log(1 + (irx['Close'] / 100)) # divide by 100 since it's %\n",
    "    irx['Log Return'] = irx['Annaul Log Return'] / DAYS_IN_YEAR\n",
    "    return irx\n",
    "\n",
    "\n",
    "def get_sharp_ratio(ticker: str, start: datetime, end: datetime):\n",
    "    \"\"\" Get sharp ratio for a stock ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): the ticker symbol on Yahoo Finance.\n",
    "        start (datetime): start time of data.\n",
    "        end (datatime): end time of data.\n",
    "\n",
    "    Returns:\n",
    "        float: the sharp ratio of the ticker data.\n",
    "    \"\"\"\n",
    "    ticker_data = get_ticker_data(ticker, start, end)\n",
    "    irx_data = get_risk_free_return(start, end)\n",
    "    ticker_data['Excess Return'] = ticker_data['Log Return'] - irx_data['Log Return']\n",
    "\n",
    "    excess_return_mean = np.mean(ticker_data['Excess Return'])\n",
    "    excess_return_std = np.std(ticker_data['Excess Return'])\n",
    "    return excess_return_mean / excess_return_std\n",
    "\n",
    "\n",
    "def get_expect_log_return(ticker: str, start: datetime, end: datetime):\n",
    "    \"\"\" Get expected log return and standard deviation for a stock ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): the ticker symbol on Yahoo Finance.\n",
    "        start (datetime): start time of data.\n",
    "        end (datatime): end time of data.\n",
    "\n",
    "    Returns:\n",
    "        float: the expected log return of the stock.\n",
    "        float: the standard deviation of log return.\n",
    "    \"\"\"\n",
    "\n",
    "    ticker_data = get_ticker_data(ticker, start, end)\n",
    "    return (np.mean(ticker_data['Log Return']), np.std(ticker_data['Log Return']))\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "## Index ETFs Sharp Ratio Analysis\n",
    "\n",
    "Calculate the Sharpe ratio of each ETF and compare it with the Sharpe ratio for the S&P 500 index (symbol\n",
    "Ë†GSPC)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SP500  sharp: 0.115277\nIBUY   sharp: 0.312674 || relative_sharp: 0.197397\nARKF   sharp: 0.280109 || relative_sharp: 0.164832\nARKW   sharp: 0.255015 || relative_sharp: 0.139738\nESPO   sharp: 0.241484 || relative_sharp: 0.126207\nTAN    sharp: 0.237422 || relative_sharp: 0.122145\nARKK   sharp: 0.235704 || relative_sharp: 0.120427\nARKG   sharp: 0.201813 || relative_sharp: 0.086536\nXRT    sharp: 0.200940 || relative_sharp: 0.085663\nARKQ   sharp: 0.199834 || relative_sharp: 0.084557\nXLY    sharp: 0.193831 || relative_sharp: 0.078554\nCLOU   sharp: 0.180409 || relative_sharp: 0.065132\nITB    sharp: 0.173852 || relative_sharp: 0.058575\nVGT    sharp: 0.153796 || relative_sharp: 0.038519\nIYT    sharp: 0.140279 || relative_sharp: 0.025002\nBETZ   sharp: 0.135008 || relative_sharp: 0.019731\nXBI    sharp: 0.126391 || relative_sharp: 0.011114\nXLB    sharp: 0.125031 || relative_sharp: 0.009754\nXME    sharp: 0.101942 || relative_sharp: -0.013335\nXPH    sharp: 0.097488 || relative_sharp: -0.017789\nXLP    sharp: 0.086831 || relative_sharp: -0.028446\nXLV    sharp: 0.067112 || relative_sharp: -0.048165\nJETS   sharp: 0.037906 || relative_sharp: -0.077371\nXLF    sharp: 0.031119 || relative_sharp: -0.084158\nVNQ    sharp: 0.026809 || relative_sharp: -0.088468\nITA    sharp: 0.024321 || relative_sharp: -0.090956\nXOP    sharp: 0.022332 || relative_sharp: -0.092945\nXLE    sharp: -0.014539 || relative_sharp: -0.129816\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tickers = ['BETZ', 'VGT', 'IBUY', 'ARKK', 'ARKG', 'ARKW', 'ARKQ', 'ARKF', 'CLOU', 'ESPO', 'XBI', 'XLV', 'XPH', 'XLP', 'XLY', 'XRT', 'ITB', 'XLF', 'IYT', 'ITA', 'XOP', 'XLE', 'VNQ', 'XLB', 'TAN', 'XME', 'JETS']\n",
    "start = datetime(2020, 4, 9)\n",
    "end = datetime(2020, 9, 23)\n",
    "\n",
    "sharp_sp500 = get_sharp_ratio('^GSPC', start, end)\n",
    "datas = []\n",
    "for ticker in tickers:\n",
    "    data = {}\n",
    "    data['ticker'] = ticker\n",
    "    data['sharp'] = get_sharp_ratio(ticker, start, end)\n",
    "    data['relative_sharp'] = data['sharp'] - sharp_sp500\n",
    "    datas.append(data)\n",
    "\n",
    "print(f'{\"SP500\":6} sharp: {sharp_sp500:.6f}')\n",
    "datas.sort(key= lambda data: data['relative_sharp'], reverse=True)\n",
    "for data in datas:\n",
    "    print(f'{data[\"ticker\"]:6} sharp: {data[\"sharp\"]:.6f} || relative_sharp: {data[\"relative_sharp\"]:.6f}')\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Bonds ETFs vs. SP500\n",
    "Calculate the expectation and standard deviation of the returns for chosen bond ETF. Compare those with the S&P 500 index. Also, compare Sharpe ratio too."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nGetting data 2010-08-31 00:00:00 -> 2020-09-01 00:00:00\n^GSPC NUAG USTB CBON BND VCSH TIP VCIT HYLB KCNY IUSB HYLD HYXU NEAR IGLB LQD SHY IEF TLT ICVT CWB PFF \nSorted by sharp ratio:\nUSTB   mean: 0.013769%  std: 0.138767%  sharp: 0.055469\nVCIT   mean: 0.020879%  std: 0.341645%  sharp: 0.054505\nCWB    mean: 0.044660%  std: 0.797649%  sharp: 0.052718\nVCSH   mean: 0.011651%  std: 0.188412%  sharp: 0.050389\nICVT   mean: 0.050866%  std: 1.028362%  sharp: 0.045993\nIUSB   mean: 0.015409%  std: 0.261715%  sharp: 0.045586\nBND    mean: 0.013945%  std: 0.270118%  sharp: 0.044684\nLQD    mean: 0.021567%  std: 0.457141%  sharp: 0.042864\n\u001b[94m^GSPC  mean: 0.047859%  std: 1.092130%  sharp: 0.042609\u001b[0m\nSHY    mean: 0.004609%  std: 0.058542%  sharp: 0.039832\nIEF    mean: 0.016199%  std: 0.382890%  sharp: 0.037710\nTIP    mean: 0.013923%  std: 0.349785%  sharp: 0.034819\nIGLB   mean: 0.026119%  std: 0.702596%  sharp: 0.034132\nNUAG   mean: 0.016031%  std: 0.317004%  sharp: 0.032778\nTLT    mean: 0.027242%  std: 0.924812%  sharp: 0.027665\nPFF    mean: 0.019951%  std: 0.758842%  sharp: 0.023621\nHYLB   mean: 0.018551%  std: 0.600425%  sharp: 0.022992\nHYXU   mean: 0.014868%  std: 0.686301%  sharp: 0.016561\nNEAR   mean: 0.006071%  std: 0.180713%  sharp: 0.015384\nHYLD   mean: 0.010443%  std: 0.641194%  sharp: 0.015057\nCBON   mean: 0.005337%  std: 0.396957%  sharp: 0.004298\nKCNY   mean: 0.003258%  std: 0.432183%  sharp: -0.001589\n---------------------------------------------------------\n\nGetting data 2015-08-31 00:00:00 -> 2020-09-01 00:00:00\n^GSPC NUAG USTB CBON BND VCSH TIP VCIT HYLB KCNY IUSB HYLD HYXU NEAR IGLB LQD SHY IEF TLT ICVT CWB PFF \nSorted by sharp ratio:\nUSTB   mean: 0.013769%  std: 0.138767%  sharp: 0.055469\nCWB    mean: 0.054362%  std: 0.924893%  sharp: 0.054129\nICVT   mean: 0.059239%  std: 1.044036%  sharp: 0.053197\nVCIT   mean: 0.023661%  std: 0.373421%  sharp: 0.052245\nIUSB   mean: 0.016914%  std: 0.265389%  sharp: 0.048594\nBND    mean: 0.017463%  std: 0.314600%  sharp: 0.041606\nLQD    mean: 0.026226%  std: 0.539107%  sharp: 0.041461\nIEF    mean: 0.018081%  std: 0.343476%  sharp: 0.040555\nTIP    mean: 0.017244%  std: 0.332737%  sharp: 0.040023\nVCSH   mean: 0.013290%  std: 0.239087%  sharp: 0.038659\nIGLB   mean: 0.033470%  std: 0.780001%  sharp: 0.038032\nSHY    mean: 0.006812%  std: 0.066376%  sharp: 0.037768\n\u001b[94m^GSPC  mean: 0.045569%  std: 1.210576%  sharp: 0.036170\u001b[0m\nNUAG   mean: 0.016031%  std: 0.317004%  sharp: 0.032778\nTLT    mean: 0.032439%  std: 0.874714%  sharp: 0.032199\nHYLB   mean: 0.018551%  std: 0.600425%  sharp: 0.022992\nHYXU   mean: 0.017088%  std: 0.723000%  sharp: 0.017759\nPFF    mean: 0.017188%  std: 0.944748%  sharp: 0.014257\nNEAR   mean: 0.007162%  std: 0.210813%  sharp: 0.012472\nCBON   mean: 0.008610%  std: 0.387578%  sharp: 0.011617\nHYLD   mean: 0.010782%  std: 0.749996%  sharp: 0.010136\nKCNY   mean: 0.005595%  std: 0.440758%  sharp: 0.002365\n---------------------------------------------------------\n"
    }
   ],
   "source": [
    "tickers = ['^GSPC', 'NUAG', 'USTB', 'CBON', 'BND', 'VCSH', 'TIP', 'VCIT', 'HYLB', 'KCNY', 'IUSB', 'HYLD', 'HYXU', 'NEAR', 'IGLB', 'LQD', 'SHY', 'IEF', 'TLT', 'ICVT', 'CWB', 'PFF']\n",
    "periods = [\n",
    "    (datetime(2010, 8, 31), datetime(2020, 9, 1)),\n",
    "    (datetime(2015, 8, 31), datetime(2020, 9, 1)),\n",
    "]\n",
    "\n",
    "for start, end in periods:\n",
    "    print(f'\\nGetting data {start} -> {end}')\n",
    "\n",
    "    datas = []\n",
    "    for ticker in tickers:\n",
    "        print(f'{ticker} ', end='')\n",
    "        data = {}\n",
    "        data['ticker'] = ticker\n",
    "        data['mean'], data['std'] = get_expect_log_return(ticker, start, end)\n",
    "        data['sharp'] = get_sharp_ratio(ticker, start, end)\n",
    "        datas.append(data)\n",
    "    \n",
    "    print('\\nSorted by sharp ratio:')\n",
    "    datas.sort(key= lambda data: data['sharp'], reverse=True)\n",
    "    for data in datas:\n",
    "        color_prefix = '\\x1b[94m' if data['ticker'] == '^GSPC' else ''\n",
    "        color_postfix = '\\x1b[0m' if data['ticker'] == '^GSPC' else ''\n",
    "        print(f'{color_prefix}{data[\"ticker\"]:6} mean: {data[\"mean\"]*100:.6f}%  std: {data[\"std\"]*100:.6f}%' +\n",
    "              f'  sharp: {data[\"sharp\"]:.6f}{color_postfix}')\n",
    "    print('---------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sp500 sharp 5yr/10yr = 0.8488676576428935\n"
    }
   ],
   "source": [
    "sp500_10yr_sharp = get_sharp_ratio('^GSPC', datetime(2010, 8, 31), datetime(2020, 9, 1))\n",
    "sp500_5yr_sharp = get_sharp_ratio('^GSPC', datetime(2015, 8, 31), datetime(2020, 9, 1))\n",
    "print(f'sp500 sharp 5yr/10yr = {sp500_5yr_sharp / sp500_10yr_sharp}')"
   ]
  },
  {
   "source": [
    "# Short Selling\n",
    "Calculate the returns for asset over 2 month windows by using its price on a given day and its price 42 days prior. Note that for each day of\n",
    "returns, there is a different two month window behind it. Also analyze:\n",
    "-  The mean return of a asset over all of the 2 month windows.\n",
    "-  The percentage of those 2 month windows yield negative returns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nGetting data 2020-04-09 00:00:00 -&gt; 2020-10-03 00:00:00\n^GSPC IVV QQQ IJR IJH SHY IEF TLT JETS VGT CLOU XBI XPH XLV XLP XLY XRT ITB XLF KRE XLI IYT ITA XLE XOP VNQ XLU XLB XME DBA CORN SOYB WEAT \nSorted by the percentage of negative log returns in all windows:\nXLE    rolling_mean: -0.029255% rolling_neg_pct: 73.170732%\nXOP    rolling_mean: -0.004161% rolling_neg_pct: 63.414634%\nTLT    rolling_mean: 0.001060% rolling_neg_pct: 53.658537%\nWEAT   rolling_mean: 0.003819% rolling_neg_pct: 39.024390%\nCORN   rolling_mean: 0.018614% rolling_neg_pct: 37.804878%\nIEF    rolling_mean: 0.003190% rolling_neg_pct: 35.365854%\nXBI    rolling_mean: 0.065458% rolling_neg_pct: 34.146341%\nKRE    rolling_mean: 0.033262% rolling_neg_pct: 34.146341%\nITA    rolling_mean: 0.034101% rolling_neg_pct: 28.048780%\nXLU    rolling_mean: 0.019002% rolling_neg_pct: 28.048780%\nDBA    rolling_mean: 0.032655% rolling_neg_pct: 24.390244%\nJETS   rolling_mean: 0.097821% rolling_neg_pct: 20.731707%\nXLV    rolling_mean: 0.033413% rolling_neg_pct: 20.731707%\nXPH    rolling_mean: 0.029221% rolling_neg_pct: 17.073171%\nXLF    rolling_mean: 0.049673% rolling_neg_pct: 17.073171%\nVNQ    rolling_mean: 0.043682% rolling_neg_pct: 15.853659%\nIJR    rolling_mean: 0.082565% rolling_neg_pct: 13.414634%\nIJH    rolling_mean: 0.075944% rolling_neg_pct: 9.756098%\nSHY    rolling_mean: 0.000599% rolling_neg_pct: 8.536585%\nXLP    rolling_mean: 0.053406% rolling_neg_pct: 8.536585%\nSOYB   rolling_mean: 0.049635% rolling_neg_pct: 4.878049%\nXME    rolling_mean: 0.118317% rolling_neg_pct: 3.658537%\nCLOU   rolling_mean: 0.127869% rolling_neg_pct: 2.439024%\nXLI    rolling_mean: 0.100097% rolling_neg_pct: 2.439024%\nXLB    rolling_mean: 0.103104% rolling_neg_pct: 1.219512%\n\u001b[94m^GSPC  rolling_mean: 0.076560% rolling_neg_pct: 0.000000%\u001b[0m\nIVV    rolling_mean: 0.079636% rolling_neg_pct: 0.000000%\nQQQ    rolling_mean: 0.117742% rolling_neg_pct: 0.000000%\nVGT    rolling_mean: 0.120661% rolling_neg_pct: 0.000000%\nXLY    rolling_mean: 0.116691% rolling_neg_pct: 0.000000%\nXRT    rolling_mean: 0.163313% rolling_neg_pct: 0.000000%\nITB    rolling_mean: 0.201578% rolling_neg_pct: 0.000000%\nIYT    rolling_mean: 0.143020% rolling_neg_pct: 0.000000%\n---------------------------------------------------------\n"
    }
   ],
   "source": [
    "def get_log_return_sliding_window(ticker: str, start: datetime, end: datetime, window_size: int):\n",
    "    \"\"\" \n",
    "    Get log return for each time window. For window size = x, an entry will contain the log return from date d - x to d. \n",
    "    Next entry contains d + 1 - x to d + 1.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): the ticker symbol on Yahoo Finance.\n",
    "        start (datetime): start time of data.\n",
    "        end (datatime): end time of data.\n",
    "        window_size (int): the size of the window.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: contains the log return in each window.\n",
    "    \"\"\"\n",
    "    ticker_data = get_ticker_data(ticker, start, end)\n",
    "    ticker_data['Rolling Start Date'] = ticker_data.index.shift(periods=-1 * (window_size), freq='B')\n",
    "    ticker_data['Rolling End Date'] = ticker_data.index\n",
    "    ticker_data['Rolling Log Return'] = ticker_data['Log Return'].rolling(window_size).sum()\n",
    "    ticker_data.dropna(subset=['Rolling Log Return'], inplace=True)\n",
    "    return ticker_data\n",
    "\n",
    "tickers = ['^GSPC', 'IVV', 'QQQ', 'IJR', 'IJH', 'SHY', 'IEF', 'TLT', 'JETS', 'VGT', 'CLOU', 'XBI', 'XPH', 'XLV', 'XLP', 'XLY', 'XRT', 'ITB', 'XLF', 'KRE', 'XLI', 'IYT', 'ITA', 'XLE', 'XOP', 'VNQ', 'XLU', 'XLB', 'XME', 'DBA', 'CORN', 'SOYB', 'WEAT']\n",
    "start = datetime(2010, 8, 31)\n",
    "end = datetime(2020, 9, 1)\n",
    "window_size = 42\n",
    "datas = []\n",
    "\n",
    "print(f'\\nGetting data {start} -> {end}')\n",
    "for ticker in tickers:\n",
    "    print(f'{ticker} ', end='')\n",
    "    data = {}\n",
    "    data['ticker'] = ticker\n",
    "\n",
    "    ticker_data = get_log_return_sliding_window(ticker, start, end, window_size)\n",
    "    data['rolling_mean'] = np.mean(ticker_data['Rolling Log Return'])\n",
    "\n",
    "    rolling_neg_cnt = (ticker_data['Rolling Log Return'] < 0).sum()\n",
    "    data['rolling_neg_pct'] =  rolling_neg_cnt / ticker_data['Rolling Log Return'].size * 100\n",
    "    datas.append(data)\n",
    "\n",
    "print('\\nSorted by the percentage of negative log returns in all windows:')\n",
    "datas.sort(key= lambda data: data['rolling_neg_pct'], reverse=True)\n",
    "for data in datas:\n",
    "    color_prefix = '\\x1b[94m' if data['ticker'] == '^GSPC' else ''\n",
    "    color_postfix = '\\x1b[0m' if data['ticker'] == '^GSPC' else ''\n",
    "    print(f'{color_prefix}{data[\"ticker\"]:6} rolling_mean: {data[\"rolling_mean\"]:.6f}%'+ \n",
    "            f' rolling_neg_pct: {data[\"rolling_neg_pct\"]:.6f}%{color_postfix}')\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, 3, 8])\n",
    "dataframe = pd.DataFrame({'A': [1,2,3,4], 'B': [3,3,3,3]})\n",
    "dataframe2 = pd.DataFrame({'A': [1,2,3,4,5,6,7,8], 'B': [3,3,3,3,6,6,6,6]})\n",
    "print (dataframe - dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "            A  B  C  D\n2013-01-08 -2 -2 -5 -2\n2013-01-09 -1  3  2  0\n2013-01-10 -1  4 -4 -3\n2013-01-11  4  0  1  4\n2013-01-12 -1  4 -5  0\n2013-01-13  2 -4  1  2\n4\n6\n"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(np.random.randint(-5, 5, size=(6, 4)), index=pd.date_range('20130108', periods=6), columns=list('ABCD'))\n",
    "# df2 = pd.DataFrame(np.zeros((20, 4)), index=pd.date_range('20130101', periods=20), columns=list('ABCD'))\n",
    "\n",
    "print (df)\n",
    "\n",
    "pct = (df['A'] < 0).sum()\n",
    "print(pct)\n",
    "print(df['A'].size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-analysis-env",
   "language": "python",
   "name": "stock-analysis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}